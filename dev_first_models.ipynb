{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19962238",
   "metadata": {},
   "source": [
    "## First models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c84bad",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3fbc3733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bapti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\bapti\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "import time\n",
    "\n",
    "import ast\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c56b2b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/train.txt\", names=[\"text\", \"emotion\"], sep=\";\")\n",
    "df_test = pd.read_csv(\"data/test.txt\", names=[\"text\", \"emotion\"], sep=\";\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3ec7d7",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "17e41c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stopwords\n",
    "sw_file = open('misc/stopwords.txt', \"r\")\n",
    "try :\n",
    "    content = sw_file.read()\n",
    "    stopwords = ast.literal_eval(content)\n",
    "finally:\n",
    "    sw_file.close()\n",
    "    \n",
    "# separate text and labels\n",
    "X, y = list(df_train['text']), list(df_train['emotion'])\n",
    "\n",
    "# Turn labels to numeric\n",
    "emotion_list = list(df_train['emotion'].unique())\n",
    "y = [emotion_list.index(em) for em in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7006f002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed : 0.85 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess(text_lst, sw=False, stem=False, lem=True):\n",
    "    \"\"\"\n",
    "    Apply different preprocessing.\n",
    "    returns :\n",
    "        - list of texts preprocessed\n",
    "    params : \n",
    "        - list(str) text_lst : list of text to preprocess\n",
    "        - bool sw : enable to remove stopwords\n",
    "        - bool stem : enable to stem text\n",
    "        - bool lem : enable to lemmatize text\n",
    "    \"\"\"\n",
    "    time_start = time.time()\n",
    "    if sw :\n",
    "        text_lst = [' '.join([word for word in x.split() if word not in (stopwords)]) for x in text_lst]\n",
    "    \n",
    "    if stem :\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        text_lst = [' '.join([stemmer.stem(word) for word in x.split()]) for x in text_lst]\n",
    "        \n",
    "    elif lem :\n",
    "        lem = WordNetLemmatizer()\n",
    "        text_lst = [' '.join([lem.lemmatize(word) for word in x.split()]) for x in text_lst]\n",
    "    \n",
    "    print(f'Time elapsed : {round(time.time() - time_start, 2)} s')\n",
    "    \n",
    "    return text_lst\n",
    "\n",
    "X_preproc = preprocess(X, sw=True, stem=False, lem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d124d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32e740c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "246993cd",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da526924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0054be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5bddcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
