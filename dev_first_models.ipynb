{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19962238",
   "metadata": {},
   "source": [
    "## First models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c84bad",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3fbc3733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bapti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\bapti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bapti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "import time\n",
    "\n",
    "import ast\n",
    "from collections import Counter\n",
    "\n",
    "from nrclex import NRCLex\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c56b2b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/train.txt\", names=[\"text\", \"emotion\"], sep=\";\")\n",
    "df_test = pd.read_csv(\"data/test.txt\", names=[\"text\", \"emotion\"], sep=\";\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3ec7d7",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17e41c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stopwords\n",
    "sw_file = open('misc/stopwords.txt', \"r\")\n",
    "try :\n",
    "    content = sw_file.read()\n",
    "    stopwords = ast.literal_eval(content)\n",
    "finally:\n",
    "    sw_file.close()\n",
    "    \n",
    "# separate text and labels\n",
    "X, y = list(df_train['text']), list(df_train['emotion'])\n",
    "\n",
    "# Turn labels to numeric\n",
    "emotion_list = list(df_train['emotion'].unique())\n",
    "y = [emotion_list.index(em) for em in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7006f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(text_lst, sw=False, stem=False, lem=True):\n",
    "    \"\"\"\n",
    "    Apply different preprocessing.\n",
    "    returns :\n",
    "        - list of texts preprocessed\n",
    "    params : \n",
    "        - list(str) text_lst : list of text to preprocess\n",
    "        - bool sw : enable to remove stopwords\n",
    "        - bool stem : enable to stem text\n",
    "        - bool lem : enable to lemmatize text\n",
    "    \"\"\"\n",
    "    time_start = time.time()\n",
    "    if sw :\n",
    "        text_lst = [' '.join([word for word in x.split() if word not in (stopwords)]) for x in text_lst]\n",
    "    \n",
    "    stemmer = SnowballStemmer('english')\n",
    "    lem = WordNetLemmatizer()\n",
    "    \n",
    "    if stem and lem :\n",
    "        text_lst = [' '.join([stemmer.stem(lem.lemmatize(word)) for word in x.split()]) for x in text_lst]\n",
    "    \n",
    "    elif stem :\n",
    "        text_lst = [' '.join([stemmer.stem(word) for word in x.split()]) for x in text_lst]\n",
    "        \n",
    "    elif lem :\n",
    "        text_lst = [' '.join([lem.lemmatize(word) for word in x.split()]) for x in text_lst]\n",
    "    \n",
    "    print(f'Time elapsed : {round(time.time() - time_start, 2)} s')\n",
    "    \n",
    "    return text_lst\n",
    "\n",
    "#X_preproc = preprocess(X, sw=False, stem=True, lem=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246993cd",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dd756a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing function\n",
    "def test_results():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ade0d8",
   "metadata": {},
   "source": [
    "#### #1 Algorithm without training on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0054be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed : 0.85 s\n",
      "im grabbing a minute to post i feel greedy wrong\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# simply lemma applied\n",
    "X_preproc = preprocess(X, sw=False, stem=False, lem=True)\n",
    "\n",
    "print(X_preproc[2])\n",
    "text_obj = NRCLex(X_preproc[0])\n",
    "print(text_obj.raw_emotion_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5bddcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aad8b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef018fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94dd67b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
